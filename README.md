# WhiteBox-Part2

# Dataset
1. [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic) (Classification)
2. [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/description) (Regression)

# Model 
1. Linear Regression
2. Decision Tree
3. Random Forest
4. XGboost
5. Deep Neural Network (Pytorch)

# Intepretable Methods
## Partial Dependence Plot (PDP)
- **Paper**
  Friedman, Jerome H. “[Greedy function approximation: A gradient boosting machine.](http://docs.salford-systems.com/GreedyFuncApproxSS.pdf)” Annals of statistics (2001): 1189-1232.
- [] PDP에 대한 설명
- [] PDP example notebook

## Individual Conditional Expectation (ICE)
- **Paper**   
  Goldstein, Alex, et al. “[Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation.](https://arxiv.org/pdf/1309.6392.pdf)” Journal of Computational and Graphical Statistics 24.1 (2015): 44-65.
- [] ICE에 대한 설명
- [] ICE example notebook

## Local interpretable model-agnostic explanations (LIME)
- **Paper**
  Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. “[Why should I trust you?: Explaining the predictions of any classifier.](https://arxiv.org/pdf/1602.04938.pdf)” Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. ACM (2016).
- [] LIME에 대한 설명
- [] LIME example notebook

## SHapley Additive exPlanations (SHAP)
- **Paper**
  Lundberg, Scott M., and Su-In Lee. “[A unified approach to interpreting model predictions.](https://arxiv.org/pdf/1705.07874.pdf)” Advances in Neural Information Processing Systems. 2017.
- [] SHAP에 대한 설명
- [] SHAP example notebook

# Results


# Conclusion
